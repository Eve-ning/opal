{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect(\"data.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation\n",
    "\n",
    "Fetch from the DB and process our UID (User ID) and MID (Map ID)\n",
    "- For each distinct `speed` & `map`, we set a separate `mid`\n",
    "- For each distinct `create_at_year` (year played) & `player`, we set a separate `uid`.\n",
    "\n",
    "**Note:**\n",
    "- `speed`: `{-1: HT, 1: DT, 0: Otherwise}`\n",
    "- `create_at`: is in unix time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(con.execute(\n",
    "    \"SELECT\"\n",
    "    \" beatmap_id, user_id, score, accuracy, speed, create_at \"\n",
    "    \"FROM Score\"\n",
    ").fetchall(), columns=['mid', 'uid', 'score', 'accuracy', 'speed', 'create_at'])\n",
    "df['create_at_year'] = pd.to_datetime(df['create_at'], unit='s').dt.year\n",
    "df['uid'] = df['uid'].astype(str) + \"/\" + df['create_at_year'].astype(str)\n",
    "df['mid'] = df['mid'].astype(str) + \"/\" + df['speed'].astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove Outliers\n",
    "We're not interested in:\n",
    "- scores below 750K as they aren't \"good\"\n",
    "- players who have played < 100 maps as there will be too little associations\n",
    "- maps who have been played by < 100 players ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = df[df['score'] > 750000]\n",
    "df = df[df.groupby('mid').mid.transform('count') >= 100]\n",
    "df = df[df.groupby('uid').uid.transform('count') >= 100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Label Encode\n",
    "\n",
    "Embeddings only take in distinct integers, our `uid` and `mid` are strings, e.g. (`uid = 1928423/2019`, `mid = 284812/-1`)\n",
    "We use `LabelEncoder` to encode them"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "uid_le = LabelEncoder()\n",
    "df['uid_le'] = uid_le.fit_transform(df['uid'])\n",
    "mid_le = LabelEncoder()\n",
    "df['mid_le'] = uid_le.fit_transform(df['mid'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the Net\n",
    "\n",
    "Refer to [**this paper**](https://towardsdatascience.com/paper-review-neural-collaborative-filtering-explanation-implementation-ea3e031b7f96)\n",
    "\n",
    "- `X_X_emb`: Embedding Layers\n",
    "- `mf_net`: GMF Layer\n",
    "- `mlp_net`: MLP Layer\n",
    "- `neu_mf_net`: NeuMF Layer (the final concat layer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class WideDeepNet(nn.Module):\n",
    "    def __init__(self, uid_no, mid_no, deep_emb_dim, deep_chn_out):\n",
    "        super(WideDeepNet, self).__init__()\n",
    "\n",
    "        self.uid_no = uid_no\n",
    "        self.mid_no = mid_no\n",
    "        self.wide_net = nn.Sequential()\n",
    "\n",
    "        self.u_deep_emb = nn.Embedding(uid_no, deep_emb_dim)\n",
    "        self.m_deep_emb = nn.Embedding(mid_no, deep_emb_dim)\n",
    "        self.deep_net = nn.Sequential(\n",
    "            nn.Linear(deep_emb_dim, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(8, deep_chn_out),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.comb_net = nn.Sequential(\n",
    "            nn.Linear(uid_no + mid_no + deep_chn_out, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "\n",
    "    def forward(self, uid, mid):\n",
    "        u_wide_emb = nn.functional.one_hot(uid, self.uid_no)\n",
    "        m_wide_emb = nn.functional.one_hot(mid, self.mid_no)\n",
    "        # u_wide_emb = self.u_wide_emb(uid)\n",
    "        # m_wide_emb = self.m_wide_emb(mid)\n",
    "        wide_out = self.wide_net(torch.concat([u_wide_emb, m_wide_emb], dim=-1))\n",
    "\n",
    "        u_deep_emb = self.u_deep_emb(uid)\n",
    "        m_deep_emb = self.m_deep_emb(mid)\n",
    "        deep_out = self.deep_net(torch.mul(u_deep_emb, m_deep_emb))\n",
    "\n",
    "        pred = self.comb_net(torch.concat([wide_out, deep_out], dim=-1))\n",
    "\n",
    "        return pred[:,:,0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.6677],\n        [0.6640],\n        [0.6468],\n        [0.6353],\n        [0.6670]], grad_fn=<SelectBackward0>)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WideDeepNet(128, 128, 100, 100)(torch.randint(0, 100, [5, 1]), torch.randint(0, 100, [5, 1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataLoaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch import Tensor\n",
    "\n",
    "x_uid = Tensor(df[['uid_le']].values).to(int)\n",
    "x_mid = Tensor(df[['mid_le']].values).to(int)\n",
    "y = Tensor(df[['accuracy']].values)\n",
    "ds = TensorDataset(x_uid, x_mid, y)\n",
    "train_size = int(len(ds) * 0.7)\n",
    "val_size = int(len(ds) * 0.2)\n",
    "test_size = len(ds) - train_size - val_size\n",
    "train_set, val_set, test_set = random_split(ds, [train_size, val_size, test_size])\n",
    "train_dl = DataLoader(train_set, batch_size=16, shuffle=True, num_workers=4)\n",
    "val_dl = DataLoader(val_set, batch_size=16, num_workers=4)\n",
    "test_dl = DataLoader(test_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Net Wrapper\n",
    "\n",
    "PyTorch-Lightning wrapper makes it easier to train & visualize."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "# SEE Desmos: https://www.desmos.com/calculator/f7tlysna7c\n",
    "def adj_inv_sigmoid(x):\n",
    "    return -torch.log(1 / ((x / 2.5) + 0.5) - 1)\n",
    "\n",
    "\n",
    "def adj_sigmoid(x):\n",
    "    return -(0.5 * torch.exp(-x) - 0.5)/ (0.4 * (torch.exp(-x) + 1))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.0000])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_inv_sigmoid(adj_sigmoid(torch.ones([1])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LitNet(pl.LightningModule):\n",
    "    def __init__(self, uid_no, mid_no, deep_emb_dim, deep_chn_out):\n",
    "        super().__init__()\n",
    "        self.model = WideDeepNet(uid_no, mid_no, deep_emb_dim, deep_chn_out)\n",
    "\n",
    "    def forward(self, uid, mid):\n",
    "        return self.model(uid, mid)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_uid, x_mid, y = batch\n",
    "        y_hat = self(x_uid, x_mid)\n",
    "        y_adj = adj_inv_sigmoid(y)\n",
    "        loss = torch.sqrt(((y_hat - y_adj) ** 2).mean())\n",
    "        self.log(\"train_mae\", torch.abs(adj_sigmoid(y_hat) - adj_sigmoid(y_adj)).mean())\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_uid, x_mid, y = batch\n",
    "        y_hat = self(x_uid, x_mid)\n",
    "        y_adj = adj_inv_sigmoid(y)\n",
    "        # self.log(\"val_rmse\", adj_sigmoid(y_del ** 2).mean())\n",
    "        self.log(\"val_mae\", torch.abs(adj_sigmoid(y_hat) - adj_sigmoid(y_adj)).mean())\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0005, weight_decay=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | WideDeepNet | 174 K \n",
      "--------------------------------------\n",
      "174 K     Trainable params\n",
      "0         Non-trainable params\n",
      "174 K     Total params\n",
      "0.699     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20c1eb11c69d409395734e448d92ca9b"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.01300048828125,
       "ncols": null,
       "nrows": null,
       "prefix": "Sanity Checking",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "453fb24537a84a04a6a2bf374bcaef3a"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.01400136947631836,
       "ncols": null,
       "nrows": null,
       "prefix": "Training",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnc\\anaconda3\\envs\\opal\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_mae\", min_delta=0.00, patience=3, verbose=False, mode=\"min\")\n",
    "uids = df['uid'].unique()\n",
    "mids = df['mid'].unique()\n",
    "uid_no = len(uids)\n",
    "mid_no = len(mids)\n",
    "net = LitNet(uid_no, mid_no, 16, 16)\n",
    "trainer = pl.Trainer(max_epochs=40,\n",
    "                     accelerator='gpu',\n",
    "                     callbacks=[early_stop_callback]\n",
    "                     )\n",
    "trainer.fit(net, train_dataloaders=train_dl, val_dataloaders=val_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}