{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect(\"data.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation\n",
    "\n",
    "Fetch from the DB and process our UID (User ID) and MID (Map ID)\n",
    "- For each distinct `speed` & `map`, we set a separate `mid`\n",
    "- For each distinct `create_at_year` (year played) & `player`, we set a separate `uid`.\n",
    "\n",
    "**Note:**\n",
    "- `speed`: `{-1: HT, 1: DT, 0: Otherwise}`\n",
    "- `create_at`: is in unix time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(con.execute(\n",
    "    \"SELECT\"\n",
    "    \" beatmap_id, user_id, score, accuracy, speed, create_at \"\n",
    "    \"FROM Score\"\n",
    ").fetchall(), columns=['mid', 'uid', 'score', 'accuracy', 'speed', 'create_at'])\n",
    "df['create_at_year'] = pd.to_datetime(df['create_at'], unit='s').dt.year\n",
    "df['uid'] = df['uid'].astype(str) + \"/\" + df['create_at_year'].astype(str)\n",
    "df['mid'] = df['mid'].astype(str) + \"/\" + df['speed'].astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove Outliers\n",
    "We're not interested in:\n",
    "- scores below 750K as they aren't \"good\"\n",
    "- players who have played < 100 maps as there will be too little associations\n",
    "- maps who have been played by < 100 players ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3874616\n",
      "2785274\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = df[df['score'] > 750000]\n",
    "df = df[df.groupby('mid').mid.transform('count') >= 25]\n",
    "df = df[df.groupby('uid').uid.transform('count') >= 25]\n",
    "print(len(df))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Label Encode\n",
    "\n",
    "Embeddings only take in distinct integers, our `uid` and `mid` are strings, e.g. (`uid = 1928423/2019`, `mid = 284812/-1`)\n",
    "We use `LabelEncoder` to encode them"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "uid_le = LabelEncoder()\n",
    "df['uid_le'] = uid_le.fit_transform(df['uid'])\n",
    "mid_le = LabelEncoder()\n",
    "df['mid_le'] = uid_le.fit_transform(df['mid'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the Net\n",
    "\n",
    "Refer to [**this paper**](https://towardsdatascience.com/paper-review-neural-collaborative-filtering-explanation-implementation-ea3e031b7f96)\n",
    "\n",
    "- `X_X_emb`: Embedding Layers\n",
    "- `mf_net`: GMF Layer\n",
    "- `mlp_net`: MLP Layer\n",
    "- `neu_mf_net`: NeuMF Layer (the final concat layer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.8117]], grad_fn=<SelectBackward0>)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class NeuMFNet(nn.Module):\n",
    "    def __init__(self, uid_no, mid_no, mf_emb_dim, mlp_emb_dim, mlp_chn_out):\n",
    "        super(NeuMFNet, self).__init__()\n",
    "\n",
    "        self.u_mf_emb = nn.Embedding(uid_no, mf_emb_dim)\n",
    "        self.m_mf_emb = nn.Embedding(mid_no, mf_emb_dim)\n",
    "        self.mf_net = nn.Sequential(\n",
    "            nn.Linear(mlp_emb_dim, mlp_emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(mlp_emb_dim, mlp_emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "        self.u_mlp_emb = nn.Embedding(uid_no, mlp_emb_dim)\n",
    "        self.m_mlp_emb = nn.Embedding(mid_no, mlp_emb_dim)\n",
    "        self.mlp_net = nn.Sequential(\n",
    "            nn.Linear(mlp_emb_dim * 2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(32, mlp_chn_out),\n",
    "        )\n",
    "        self.neu_mf_net = nn.Sequential(\n",
    "            nn.Linear(mlp_chn_out + mf_emb_dim, 1),\n",
    "            nn.Softplus(),\n",
    "        )\n",
    "\n",
    "    def forward(self, uid, mid):\n",
    "        u_mf_emb = self.u_mf_emb(uid)\n",
    "        m_mf_emb = self.m_mf_emb(mid)\n",
    "        mf_out = self.mf_net(torch.mul(u_mf_emb, m_mf_emb))\n",
    "\n",
    "        u_mlp_emb = self.u_mlp_emb(uid)\n",
    "        m_mlp_emb = self.m_mlp_emb(mid)\n",
    "        mlp_out = self.mlp_net(torch.concat([u_mlp_emb, m_mlp_emb], dim=-1))\n",
    "\n",
    "        pred = self.neu_mf_net(torch.concat([mf_out, mlp_out], dim=-1))\n",
    "\n",
    "        return pred[:, :, 0]\n",
    "\n",
    "NeuMFNet(128, 128, 16, 16, 16)(torch.randint(0, 100, [1, 1]), torch.randint(0, 100, [1, 1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataLoaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch import Tensor\n",
    "\n",
    "x_uid = Tensor(df[['uid_le']].values).to(int)\n",
    "x_mid = Tensor(df[['mid_le']].values).to(int)\n",
    "y = Tensor(df[['accuracy']].values)\n",
    "ds = TensorDataset(x_uid, x_mid, y)\n",
    "train_size = int(len(ds) * 0.7)\n",
    "val_size = int(len(ds) * 0.2)\n",
    "test_size = len(ds) - train_size - val_size\n",
    "train_set, val_set, test_set = random_split(ds, [train_size, val_size, test_size])\n",
    "train_dl = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=4)\n",
    "val_dl = DataLoader(val_set, batch_size=256, num_workers=4)\n",
    "test_dl = DataLoader(test_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Net Wrapper\n",
    "\n",
    "PyTorch-Lightning wrapper makes it easier to train & visualize."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "# SEE Desmos: https://www.desmos.com/calculator/f7tlysna7c\n",
    "def adj_inv_sigmoid(x):\n",
    "    return -torch.log(1 / ((x / 2.5) + 0.5) - 1)\n",
    "\n",
    "\n",
    "def adj_sigmoid(x):\n",
    "    return -(0.5 * torch.exp(-x) - 0.5) / (0.4 * (torch.exp(-x) + 1))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.0000])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_inv_sigmoid(adj_sigmoid(torch.ones([1])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "class LitNet(pl.LightningModule):\n",
    "    def __init__(self, uid_no, mid_no, mf_emb_dim, mlp_emb_dim, mlp_chn_out):\n",
    "        super().__init__()\n",
    "        self.model = NeuMFNet(uid_no, mid_no, mf_emb_dim, mlp_emb_dim, mlp_chn_out)\n",
    "\n",
    "    def forward(self, uid, mid):\n",
    "        return self.model(uid, mid)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_uid, x_mid, y = batch\n",
    "        y_hat = self(x_uid, x_mid)\n",
    "        y_adj = adj_inv_sigmoid(y)\n",
    "        loss = torch.sqrt(((y_hat - y_adj) ** 2).mean())\n",
    "        self.log(\"train_mae\", torch.abs(adj_sigmoid(y_hat) - adj_sigmoid(y_adj)).mean())\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_uid, x_mid, y = batch\n",
    "        y_hat = self(x_uid, x_mid)\n",
    "        y_adj = adj_inv_sigmoid(y)\n",
    "        # self.log(\"val_rmse\", adj_sigmoid(y_del ** 2).mean())\n",
    "        self.log(\"val_mae\", torch.abs(adj_sigmoid(y_hat) - adj_sigmoid(y_adj)).mean())\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(self.parameters(), lr=0.0005, weight_decay=0.001)\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optim,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": ReduceLROnPlateau(optim, mode='min', factor=0.2, patience=2, verbose=True),\n",
    "                \"monitor\": \"val_mae\",\n",
    "            },\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "uids = df['uid'].unique()\n",
    "mids = df['mid'].unique()\n",
    "uid_no = len(uids)\n",
    "mid_no = len(mids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "net = LitNet(uid_no, mid_no, 256, 256, 128)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | NeuMFNet | 27.3 M\n",
      "-----------------------------------\n",
      "27.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "27.3 M    Total params\n",
      "109.048   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e840a45c4d544981820918beef6e2cf4"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.014077901840209961,
       "ncols": null,
       "nrows": null,
       "prefix": "Sanity Checking",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68e297bc6c194f64a8c6d5aa3e847937"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.018338680267333984,
       "ncols": null,
       "nrows": null,
       "prefix": "Training",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d75cf4fb90084de0821b0f5da177f564"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.01324319839477539,
       "ncols": null,
       "nrows": null,
       "prefix": "Validation",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3237a32f871b46aeb907f937fbefdcd2"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.01599740982055664,
       "ncols": null,
       "nrows": null,
       "prefix": "Validation",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b879b3073b14e78920aad8cbd2db604"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.014106273651123047,
       "ncols": null,
       "nrows": null,
       "prefix": "Validation",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb3cdcbb97164b4693559d93de904ec9"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.015269756317138672,
       "ncols": null,
       "nrows": null,
       "prefix": "Validation",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44c14c20cf5f4f40ab15c1b32d0ba03c"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.014107227325439453,
       "ncols": null,
       "nrows": null,
       "prefix": "Validation",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df3a7d4dd1f549868c2fc77c84b17766"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.01312875747680664,
       "ncols": null,
       "nrows": null,
       "prefix": "Validation",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnc\\anaconda3\\envs\\opal\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_mae\", min_delta=0.00, patience=5, verbose=False, mode=\"min\")\n",
    "trainer = pl.Trainer(max_epochs=40,\n",
    "                     accelerator='gpu',\n",
    "                     callbacks=[early_stop_callback]\n",
    "                     )\n",
    "trainer.fit(net, train_dataloaders=train_dl, val_dataloaders=val_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}