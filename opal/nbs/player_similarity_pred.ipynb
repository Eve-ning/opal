{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by_score_year 887452 -> 541019\n",
      "by_sr 541019 -> 541019\n",
      "by_acc_filter 541019 -> 540947\n",
      "by_remove_mod 540947 -> 391549\n",
      "Users Left: 992 | Beatmaps Left: 6545\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "from opal.score.dataset import Dataset\n",
    "from opal.score.preprocessing_dynamic import PreprocessingDynamic\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_path = Path(\"../../data/osu/scores/\")\n",
    "\n",
    "df = PreprocessingDynamic(\n",
    "    Dataset(data_path, \"top1k\").joined_filtered_df,\n",
    "    unpopular_maps_thres=None,\n",
    "    unpopular_plays_thres=None,\n",
    "    sr_min_thres=0,\n",
    "    acc_filter=(0.8, 1),\n",
    "    score_filter=None\n",
    ").filter(calc_acc=True)\n",
    "df: pd.DataFrame\n",
    "df = df.rename({'accuracy': 'acc',\n",
    "                'map_id': 'mid'}, axis=1)\n",
    "qt = QuantileTransformer()\n",
    "df['uid'] = df['user_id'].astype(str) + \"/\" + df['year'].astype(str)\n",
    "df = df[['uid', 'mid', 'acc']]\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.groupby(['uid', 'mid']).agg('mean').reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369327\n",
      "275069\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "# df = df[df['score'] > 750000]\n",
    "df = df[df.groupby('mid').mid.transform('count') >= 50]\n",
    "df = df[df.groupby('uid').uid.transform('count') >= 50]\n",
    "print(len(df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "uid_le = LabelEncoder()\n",
    "df['uid_le'] = uid_le.fit_transform(df['uid'])\n",
    "mid_le = LabelEncoder()\n",
    "df['mid_le'] = uid_le.fit_transform(df['mid'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.7075]], grad_fn=<SelectBackward0>)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class NeuMFNet(nn.Module):\n",
    "    def __init__(self, uid_no, mid_no, mf_emb_dim, mlp_emb_dim, mlp_chn_out):\n",
    "        super(NeuMFNet, self).__init__()\n",
    "\n",
    "        self.u_mf_emb = nn.Embedding(uid_no, mf_emb_dim)\n",
    "        self.m_mf_emb = nn.Embedding(mid_no, mf_emb_dim)\n",
    "        self.mf_net = nn.Sequential(\n",
    "            nn.Linear(mlp_emb_dim, mlp_emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(mlp_emb_dim, mlp_emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "        self.u_mlp_emb = nn.Embedding(uid_no, mlp_emb_dim)\n",
    "        self.m_mlp_emb = nn.Embedding(mid_no, mlp_emb_dim)\n",
    "        self.mlp_net = nn.Sequential(\n",
    "            nn.Linear(mlp_emb_dim * 2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(32, mlp_chn_out),\n",
    "        )\n",
    "        self.neu_mf_net = nn.Sequential(\n",
    "            nn.Linear(mlp_chn_out + mf_emb_dim, 1),\n",
    "            nn.Softplus(),\n",
    "        )\n",
    "\n",
    "    def forward(self, uid, mid):\n",
    "        u_mf_emb = self.u_mf_emb(uid)\n",
    "        m_mf_emb = self.m_mf_emb(mid)\n",
    "        mf_out = self.mf_net(torch.mul(u_mf_emb, m_mf_emb))\n",
    "\n",
    "        u_mlp_emb = self.u_mlp_emb(uid)\n",
    "        m_mlp_emb = self.m_mlp_emb(mid)\n",
    "        mlp_out = self.mlp_net(torch.concat([u_mlp_emb, m_mlp_emb], dim=-1))\n",
    "\n",
    "        pred = self.neu_mf_net(torch.concat([mf_out, mlp_out], dim=-1))\n",
    "\n",
    "        return pred[:, :, 0]\n",
    "\n",
    "\n",
    "NeuMFNet(128, 128, 16, 16, 16)(torch.randint(0, 100, [1, 1]), torch.randint(0, 100, [1, 1]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch import Tensor\n",
    "\n",
    "x_uid = Tensor(df[['uid_le']].values).to(int)\n",
    "x_mid = Tensor(df[['mid_le']].values).to(int)\n",
    "y = Tensor(df[['acc']].values)\n",
    "ds = TensorDataset(x_uid, x_mid, y)\n",
    "train_size = int(len(ds) * 0.7)\n",
    "val_size = int(len(ds) * 0.2)\n",
    "test_size = len(ds) - train_size - val_size\n",
    "train_set, val_set, test_set = random_split(ds, [train_size, val_size, test_size])\n",
    "train_dl = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
    "val_dl = DataLoader(val_set, batch_size=256, num_workers=2)\n",
    "test_dl = DataLoader(test_set, batch_size=256, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "# SEE Desmos: https://www.desmos.com/calculator/f7tlysna7c\n",
    "def adj_inv_sigmoid(x):\n",
    "    return -torch.log(1 / ((x / 2.5) + 0.5) - 1)\n",
    "\n",
    "\n",
    "def adj_sigmoid(x):\n",
    "    return -(0.5 * torch.exp(-x) - 0.5) / (0.4 * (torch.exp(-x) + 1))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "assert adj_inv_sigmoid(adj_sigmoid(torch.ones([1]))).item() - 1 < 1e-5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "class LitNet(pl.LightningModule):\n",
    "    def __init__(self, uid_no, mid_no, mf_emb_dim, mlp_emb_dim, mlp_chn_out):\n",
    "        super().__init__()\n",
    "        self.model = NeuMFNet(uid_no, mid_no, mf_emb_dim, mlp_emb_dim, mlp_chn_out)\n",
    "\n",
    "    def forward(self, uid, mid):\n",
    "        return self.model(uid, mid)\n",
    "\n",
    "    def training_step(self, batch: Any, batch_idx: int, dataloader_idx: int = 0) -> torch.Tensor:\n",
    "        x_uid, x_mid, y = batch\n",
    "        y_hat = self(x_uid, x_mid)\n",
    "        y_adj = adj_inv_sigmoid(y)\n",
    "\n",
    "        # We use an inv. sigmoid to make the model learn from a more linear accuracy curve.\n",
    "        # Here, we measure the loss of the pred - linearized acc\n",
    "        loss = torch.sqrt(((y_hat - y_adj) ** 2).mean())\n",
    "\n",
    "        # As we learnt the linearized acc, we need to transform it back to something interpretable\n",
    "        # We sigmoid it to make it the actual curved acc.\n",
    "        self.log(\"train_mae\", torch.abs(adj_sigmoid(y_hat) - adj_sigmoid(y_adj)).mean())\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: Any, batch_idx: int, dataloader_idx: int = 0):\n",
    "        x_uid, x_mid, y = batch\n",
    "\n",
    "        y_hat = self(x_uid, x_mid)\n",
    "        self.log(\"val_mae\", torch.abs(adj_sigmoid(y_hat) - y).mean())\n",
    "\n",
    "    def predict_step(self, batch: Any, batch_idx: int, dataloader_idx: int = 0) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        x_uid, x_mid, y = batch\n",
    "        return adj_sigmoid(self(x_uid, x_mid))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(self.parameters(), lr=0.0005, weight_decay=0.001)\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optim,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": ReduceLROnPlateau(optim, mode='min', factor=0.2, patience=2, verbose=True),\n",
    "                \"monitor\": \"val_mae\",\n",
    "            },\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "uids = df['uid'].unique()\n",
    "mids = df['mid'].unique()\n",
    "uid_no = len(uids)\n",
    "mid_no = len(mids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "net = LitNet(uid_no, mid_no, 16, 16, 8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | NeuMFNet | 313 K \n",
      "-----------------------------------\n",
      "313 K     Trainable params\n",
      "0         Non-trainable params\n",
      "313 K     Total params\n",
      "1.253     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c8b268ac4b545b894dbf4a8a3f864ba"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.01551055908203125,
       "ncols": null,
       "nrows": null,
       "prefix": "Sanity Checking",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "abcc4183184248489455c8eb82e54f70"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.01500248908996582,
       "ncols": null,
       "nrows": null,
       "prefix": "Training",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2454d24638d46878b91437e3553a555"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.013528108596801758,
       "ncols": null,
       "nrows": null,
       "prefix": "Validation",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_mae\", min_delta=0.00, patience=5, verbose=False, mode=\"min\")\n",
    "trainer = pl.Trainer(max_epochs=1,\n",
    "                     accelerator='gpu',\n",
    "                     callbacks=[early_stop_callback])\n",
    "trainer.fit(net, train_dataloaders=train_dl, val_dataloaders=val_dl)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Predicting: 753it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "683b2a15378d4017933d8ef3fec28680"
      },
      "application/json": {
       "n": 753,
       "total": null,
       "elapsed": 0.015009880065917969,
       "ncols": null,
       "nrows": null,
       "prefix": "Predicting",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 753,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = trainer.predict(net, test_dl)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "for true, pred in zip(test_dl,y_pred):\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
