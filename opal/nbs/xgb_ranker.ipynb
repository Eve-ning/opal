{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Using Scikit-Surprise\n",
    "\n",
    "Surprise!\n",
    "\n",
    "It's a well-developed CF wrapper that handles what we've just discovered, and more.\n",
    "\n",
    "Essentially it has created everything we needed.\n",
    "\n",
    "## Approach\n",
    "\n",
    "If you recall, we don't use the full dataset as it's extremely large.\n",
    "Thus, by taking a small representative sample, we can run **quick** tests that estimates the population behaviour.\n",
    "\n",
    "Then, we narrow down the best parameters after we select the best few algorithms.\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "As usual, we take a representative sample from the set.\n",
    "\n",
    "We also alter it to make it suitable for `surprise`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by_score_year 6021393 -> 3913111\n",
      "by_sr 3913111 -> 3913111\n",
      "by_remove_mod 3913111 -> 3137673\n",
      "Users Left: 9890 | Beatmaps Left: 6622\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from opal.score.dataset import Dataset as ODataset\n",
    "from opal.score.preprocessing_dynamic import PreprocessingDynamic\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_path = Path(\"../../data/osu/scores/\")\n",
    "\n",
    "df_raw = ODataset(data_path, \"top10k\").joined_filtered_df\n",
    "df = PreprocessingDynamic(\n",
    "    df_raw,\n",
    "    unpopular_maps_thres=None,\n",
    "    unpopular_plays_thres=None,\n",
    "    sr_min_thres=0,\n",
    "    acc_filter=None,\n",
    "    score_filter=None\n",
    ").filter(calc_acc=True)\n",
    "df: pd.DataFrame\n",
    "df = df.rename({'accuracy': 'acc',\n",
    "                'map_id': 'mid'}, axis=1)\n",
    "# qt = QuantileTransformer()\n",
    "# df[['acc_qt']] = qt.fit_transform(df['acc'].to_numpy().reshape(-1, 1))\n",
    "df['uid'] = df['user_id'].astype(str) + \"/\" + df['year'].astype(str)\n",
    "df = df[['uid', 'mid', 'acc']]\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.groupby(['uid', 'mid']).agg('mean').reset_index()\n",
    "df['uid'] = df['uid'].astype(str)\n",
    "df['mid'] = df['mid'].astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, uid_no, mid_no, emb_dims):\n",
    "        super(Net, self).__init__()\n",
    "        self.uid = nn.Embedding(uid_no, emb_dims)\n",
    "        self.mid = nn.Embedding(mid_no, emb_dims)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(emb_dims * 2, 1024),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 16),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, uid, mid):\n",
    "        concat = torch.concat([self.uid(uid), self.mid(mid)], dim=2)\n",
    "        return self.net(concat)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "class LitNet(pl.LightningModule):\n",
    "    def __init__(self, uid_no, mid_no, emb_dims):\n",
    "        super().__init__()\n",
    "        self.model = Net(uid_no, mid_no, emb_dims)\n",
    "        self.writer = SummaryWriter(\"lightning_logs/\")\n",
    "\n",
    "        layout = {\n",
    "            \"model\": {\n",
    "                \"loss\": [\n",
    "                    \"Multiline\",\n",
    "                    [\"loss/99\",\n",
    "                     \"loss/98\",\n",
    "                     \"loss/97\",\n",
    "                     \"loss/95\",\n",
    "                     \"loss/92\",\n",
    "                     \"loss/90\",\n",
    "                     \"loss/85\",\n",
    "                     ]],\n",
    "            },\n",
    "        }\n",
    "        self.writer.add_custom_scalars(layout)\n",
    "\n",
    "    def forward(self, uid, mid):\n",
    "        return self.model(uid, mid)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_uid, x_mid, y = batch\n",
    "        y_hat = self(x_uid, x_mid)\n",
    "        loss = torch.sqrt(((y_hat - y) ** 2).mean())\n",
    "        y = y.squeeze()[0]\n",
    "        if y > 0.99: self.writer.add_scalar(\"loss/99\", loss * 100, batch_idx)\n",
    "        if y > 0.98: self.writer.add_scalar(\"loss/98\", loss * 100, batch_idx)\n",
    "        if y > 0.97: self.writer.add_scalar(\"loss/97\", loss * 100, batch_idx)\n",
    "        if y > 0.95: self.writer.add_scalar(\"loss/95\", loss * 100, batch_idx)\n",
    "        if y > 0.92: self.writer.add_scalar(\"loss/92\", loss * 100, batch_idx)\n",
    "        if y > 0.90: self.writer.add_scalar(\"loss/90\", loss * 100, batch_idx)\n",
    "        if y > 0.85: self.writer.add_scalar(\"loss/85\", loss * 100, batch_idx)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_uid, x_mid, y = batch\n",
    "        y_hat = self(x_uid, x_mid)\n",
    "        self.log(\"val_rmse\", torch.sqrt(((y_hat - y) ** 2).mean()) * 100)\n",
    "        self.log(\"val_mae\", torch.abs(y_hat - y).mean() * 100)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0005, weight_decay=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "uids = df['uid'].unique()\n",
    "mids = df['mid'].unique()\n",
    "uid_no = len(uids)\n",
    "mid_no = len(mids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "uid_le = preprocessing.LabelEncoder()\n",
    "df['uid_le'] = uid_le.fit_transform(df['uid'])\n",
    "mid_le = preprocessing.LabelEncoder()\n",
    "df['mid_le'] = mid_le.fit_transform(df['mid'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "net = LitNet(uid_no, mid_no, 512)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch import Tensor\n",
    "\n",
    "x_uid = Tensor(df[['uid_le']].values).to(int)\n",
    "x_mid = Tensor(df[['mid_le']].values).to(int)\n",
    "y = Tensor(df[['acc']].values)\n",
    "ds = TensorDataset(x_uid, x_mid, y)\n",
    "train_size = int(len(ds) * 0.7)\n",
    "val_size = int(len(ds) * 0.2)\n",
    "test_size = len(ds) - train_size - val_size\n",
    "train_set, val_set, test_set = random_split(ds, [train_size, val_size, test_size])\n",
    "train_dl = DataLoader(train_set, batch_size=256, shuffle=True)\n",
    "val_dl = DataLoader(val_set, batch_size=256)\n",
    "test_dl = DataLoader(test_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | Net  | 17.0 M\n",
      "-------------------------------\n",
      "17.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "17.0 M    Total params\n",
      "68.026    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47b61349bb4c44c08f575a9514776514"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.012998342514038086,
       "ncols": null,
       "nrows": null,
       "prefix": "Sanity Checking",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53e174c52c2f443ca8cb565ee2785ff4"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.012002229690551758,
       "ncols": null,
       "nrows": null,
       "prefix": "Training",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# early_stop_callback = EarlyStopping(monitor=\"val_mse\", min_delta=0.00, patience=4, verbose=False, mode=\"min\")\n",
    "trainer = pl.Trainer(max_epochs=40,\n",
    "                     accelerator='gpu',\n",
    "                     # callbacks=[early_stop_callback]\n",
    "                     )\n",
    "trainer.fit(\n",
    "    net,\n",
    "    train_dataloaders=train_dl,\n",
    "    val_dataloaders=val_dl\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}